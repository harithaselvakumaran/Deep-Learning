{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dropout regularization.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMVJx2KPRMo8NasffAJMSM+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harithaselvakumaran/Deep-Learning/blob/main/dropout_regularization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywJ8-49QcCui"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "gJIOKI_JcUrH",
        "outputId": "8c84ba5d-cbc4-4652-9505-0b2cce1a5016"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-53a59d2e-1f25-4a63-aedf-e02772fe70a5\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-53a59d2e-1f25-4a63-aedf-e02772fe70a5\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving sonar_dataset.csv to sonar_dataset.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "kYuvlFBSd4ZG",
        "outputId": "56002aa0-dcda-47e9-dc84-4b4ac96c6bd1"
      },
      "source": [
        "df = pd.read_csv('sonar_dataset.csv',header=None)\n",
        "df.sample(5)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "      <th>43</th>\n",
              "      <th>44</th>\n",
              "      <th>45</th>\n",
              "      <th>46</th>\n",
              "      <th>47</th>\n",
              "      <th>48</th>\n",
              "      <th>49</th>\n",
              "      <th>50</th>\n",
              "      <th>51</th>\n",
              "      <th>52</th>\n",
              "      <th>53</th>\n",
              "      <th>54</th>\n",
              "      <th>55</th>\n",
              "      <th>56</th>\n",
              "      <th>57</th>\n",
              "      <th>58</th>\n",
              "      <th>59</th>\n",
              "      <th>60</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0.0177</td>\n",
              "      <td>0.0300</td>\n",
              "      <td>0.0288</td>\n",
              "      <td>0.0394</td>\n",
              "      <td>0.0630</td>\n",
              "      <td>0.0526</td>\n",
              "      <td>0.0688</td>\n",
              "      <td>0.0633</td>\n",
              "      <td>0.0624</td>\n",
              "      <td>0.0613</td>\n",
              "      <td>0.1680</td>\n",
              "      <td>0.3476</td>\n",
              "      <td>0.4561</td>\n",
              "      <td>0.5188</td>\n",
              "      <td>0.6308</td>\n",
              "      <td>0.7201</td>\n",
              "      <td>0.5153</td>\n",
              "      <td>0.3818</td>\n",
              "      <td>0.2644</td>\n",
              "      <td>0.3345</td>\n",
              "      <td>0.4865</td>\n",
              "      <td>0.6628</td>\n",
              "      <td>0.7389</td>\n",
              "      <td>0.9213</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.7750</td>\n",
              "      <td>0.5593</td>\n",
              "      <td>0.6172</td>\n",
              "      <td>0.8635</td>\n",
              "      <td>0.6592</td>\n",
              "      <td>0.4770</td>\n",
              "      <td>0.4983</td>\n",
              "      <td>0.3330</td>\n",
              "      <td>0.3076</td>\n",
              "      <td>0.2876</td>\n",
              "      <td>0.2226</td>\n",
              "      <td>0.0794</td>\n",
              "      <td>0.0603</td>\n",
              "      <td>0.1049</td>\n",
              "      <td>0.0606</td>\n",
              "      <td>0.1530</td>\n",
              "      <td>0.0983</td>\n",
              "      <td>0.1643</td>\n",
              "      <td>0.1901</td>\n",
              "      <td>0.1107</td>\n",
              "      <td>0.1917</td>\n",
              "      <td>0.1467</td>\n",
              "      <td>0.0392</td>\n",
              "      <td>0.0356</td>\n",
              "      <td>0.0270</td>\n",
              "      <td>0.0168</td>\n",
              "      <td>0.0102</td>\n",
              "      <td>0.0122</td>\n",
              "      <td>0.0044</td>\n",
              "      <td>0.0075</td>\n",
              "      <td>0.0124</td>\n",
              "      <td>0.0099</td>\n",
              "      <td>0.0057</td>\n",
              "      <td>0.0032</td>\n",
              "      <td>0.0019</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159</th>\n",
              "      <td>0.0235</td>\n",
              "      <td>0.0220</td>\n",
              "      <td>0.0167</td>\n",
              "      <td>0.0516</td>\n",
              "      <td>0.0746</td>\n",
              "      <td>0.1121</td>\n",
              "      <td>0.1258</td>\n",
              "      <td>0.1717</td>\n",
              "      <td>0.3074</td>\n",
              "      <td>0.3199</td>\n",
              "      <td>0.2946</td>\n",
              "      <td>0.2484</td>\n",
              "      <td>0.2510</td>\n",
              "      <td>0.1806</td>\n",
              "      <td>0.1413</td>\n",
              "      <td>0.3019</td>\n",
              "      <td>0.3635</td>\n",
              "      <td>0.3887</td>\n",
              "      <td>0.2980</td>\n",
              "      <td>0.2219</td>\n",
              "      <td>0.1624</td>\n",
              "      <td>0.1343</td>\n",
              "      <td>0.2046</td>\n",
              "      <td>0.3791</td>\n",
              "      <td>0.5771</td>\n",
              "      <td>0.7545</td>\n",
              "      <td>0.8406</td>\n",
              "      <td>0.8547</td>\n",
              "      <td>0.9036</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.9646</td>\n",
              "      <td>0.7912</td>\n",
              "      <td>0.6412</td>\n",
              "      <td>0.5986</td>\n",
              "      <td>0.6835</td>\n",
              "      <td>0.7771</td>\n",
              "      <td>0.8084</td>\n",
              "      <td>0.7426</td>\n",
              "      <td>0.6295</td>\n",
              "      <td>0.5708</td>\n",
              "      <td>0.4433</td>\n",
              "      <td>0.3361</td>\n",
              "      <td>0.3795</td>\n",
              "      <td>0.4950</td>\n",
              "      <td>0.4373</td>\n",
              "      <td>0.2404</td>\n",
              "      <td>0.1128</td>\n",
              "      <td>0.1654</td>\n",
              "      <td>0.0933</td>\n",
              "      <td>0.0225</td>\n",
              "      <td>0.0214</td>\n",
              "      <td>0.0221</td>\n",
              "      <td>0.0152</td>\n",
              "      <td>0.0083</td>\n",
              "      <td>0.0058</td>\n",
              "      <td>0.0023</td>\n",
              "      <td>0.0057</td>\n",
              "      <td>0.0052</td>\n",
              "      <td>0.0027</td>\n",
              "      <td>0.0021</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>0.0442</td>\n",
              "      <td>0.0477</td>\n",
              "      <td>0.0049</td>\n",
              "      <td>0.0581</td>\n",
              "      <td>0.0278</td>\n",
              "      <td>0.0678</td>\n",
              "      <td>0.1664</td>\n",
              "      <td>0.1490</td>\n",
              "      <td>0.0974</td>\n",
              "      <td>0.1268</td>\n",
              "      <td>0.1109</td>\n",
              "      <td>0.2375</td>\n",
              "      <td>0.2007</td>\n",
              "      <td>0.2140</td>\n",
              "      <td>0.1109</td>\n",
              "      <td>0.2036</td>\n",
              "      <td>0.2468</td>\n",
              "      <td>0.6682</td>\n",
              "      <td>0.8345</td>\n",
              "      <td>0.8252</td>\n",
              "      <td>0.8017</td>\n",
              "      <td>0.8982</td>\n",
              "      <td>0.9664</td>\n",
              "      <td>0.8515</td>\n",
              "      <td>0.6626</td>\n",
              "      <td>0.3241</td>\n",
              "      <td>0.2054</td>\n",
              "      <td>0.5669</td>\n",
              "      <td>0.5726</td>\n",
              "      <td>0.4877</td>\n",
              "      <td>0.7532</td>\n",
              "      <td>0.7600</td>\n",
              "      <td>0.5185</td>\n",
              "      <td>0.4120</td>\n",
              "      <td>0.5560</td>\n",
              "      <td>0.5569</td>\n",
              "      <td>0.1336</td>\n",
              "      <td>0.3831</td>\n",
              "      <td>0.4611</td>\n",
              "      <td>0.4330</td>\n",
              "      <td>0.2556</td>\n",
              "      <td>0.1466</td>\n",
              "      <td>0.3489</td>\n",
              "      <td>0.2659</td>\n",
              "      <td>0.0944</td>\n",
              "      <td>0.1370</td>\n",
              "      <td>0.1344</td>\n",
              "      <td>0.0416</td>\n",
              "      <td>0.0719</td>\n",
              "      <td>0.0637</td>\n",
              "      <td>0.0210</td>\n",
              "      <td>0.0204</td>\n",
              "      <td>0.0216</td>\n",
              "      <td>0.0135</td>\n",
              "      <td>0.0055</td>\n",
              "      <td>0.0073</td>\n",
              "      <td>0.0080</td>\n",
              "      <td>0.0105</td>\n",
              "      <td>0.0059</td>\n",
              "      <td>0.0105</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>136</th>\n",
              "      <td>0.1088</td>\n",
              "      <td>0.1278</td>\n",
              "      <td>0.0926</td>\n",
              "      <td>0.1234</td>\n",
              "      <td>0.1276</td>\n",
              "      <td>0.1731</td>\n",
              "      <td>0.1948</td>\n",
              "      <td>0.4262</td>\n",
              "      <td>0.6828</td>\n",
              "      <td>0.5761</td>\n",
              "      <td>0.4733</td>\n",
              "      <td>0.2362</td>\n",
              "      <td>0.1023</td>\n",
              "      <td>0.2904</td>\n",
              "      <td>0.4713</td>\n",
              "      <td>0.4659</td>\n",
              "      <td>0.1415</td>\n",
              "      <td>0.0849</td>\n",
              "      <td>0.3257</td>\n",
              "      <td>0.9007</td>\n",
              "      <td>0.9312</td>\n",
              "      <td>0.4856</td>\n",
              "      <td>0.1346</td>\n",
              "      <td>0.1604</td>\n",
              "      <td>0.2737</td>\n",
              "      <td>0.5609</td>\n",
              "      <td>0.3654</td>\n",
              "      <td>0.6139</td>\n",
              "      <td>0.5470</td>\n",
              "      <td>0.8474</td>\n",
              "      <td>0.5638</td>\n",
              "      <td>0.5443</td>\n",
              "      <td>0.5086</td>\n",
              "      <td>0.6253</td>\n",
              "      <td>0.8497</td>\n",
              "      <td>0.8406</td>\n",
              "      <td>0.8420</td>\n",
              "      <td>0.9136</td>\n",
              "      <td>0.7713</td>\n",
              "      <td>0.4882</td>\n",
              "      <td>0.3724</td>\n",
              "      <td>0.4469</td>\n",
              "      <td>0.4586</td>\n",
              "      <td>0.4491</td>\n",
              "      <td>0.5616</td>\n",
              "      <td>0.4305</td>\n",
              "      <td>0.0945</td>\n",
              "      <td>0.0794</td>\n",
              "      <td>0.0274</td>\n",
              "      <td>0.0154</td>\n",
              "      <td>0.0140</td>\n",
              "      <td>0.0455</td>\n",
              "      <td>0.0213</td>\n",
              "      <td>0.0082</td>\n",
              "      <td>0.0124</td>\n",
              "      <td>0.0167</td>\n",
              "      <td>0.0103</td>\n",
              "      <td>0.0205</td>\n",
              "      <td>0.0178</td>\n",
              "      <td>0.0187</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.0286</td>\n",
              "      <td>0.0453</td>\n",
              "      <td>0.0277</td>\n",
              "      <td>0.0174</td>\n",
              "      <td>0.0384</td>\n",
              "      <td>0.0990</td>\n",
              "      <td>0.1201</td>\n",
              "      <td>0.1833</td>\n",
              "      <td>0.2105</td>\n",
              "      <td>0.3039</td>\n",
              "      <td>0.2988</td>\n",
              "      <td>0.4250</td>\n",
              "      <td>0.6343</td>\n",
              "      <td>0.8198</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.9988</td>\n",
              "      <td>0.9508</td>\n",
              "      <td>0.9025</td>\n",
              "      <td>0.7234</td>\n",
              "      <td>0.5122</td>\n",
              "      <td>0.2074</td>\n",
              "      <td>0.3985</td>\n",
              "      <td>0.5890</td>\n",
              "      <td>0.2872</td>\n",
              "      <td>0.2043</td>\n",
              "      <td>0.5782</td>\n",
              "      <td>0.5389</td>\n",
              "      <td>0.3750</td>\n",
              "      <td>0.3411</td>\n",
              "      <td>0.5067</td>\n",
              "      <td>0.5580</td>\n",
              "      <td>0.4778</td>\n",
              "      <td>0.3299</td>\n",
              "      <td>0.2198</td>\n",
              "      <td>0.1407</td>\n",
              "      <td>0.2856</td>\n",
              "      <td>0.3807</td>\n",
              "      <td>0.4158</td>\n",
              "      <td>0.4054</td>\n",
              "      <td>0.3296</td>\n",
              "      <td>0.2707</td>\n",
              "      <td>0.2650</td>\n",
              "      <td>0.0723</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1192</td>\n",
              "      <td>0.1089</td>\n",
              "      <td>0.0623</td>\n",
              "      <td>0.0494</td>\n",
              "      <td>0.0264</td>\n",
              "      <td>0.0081</td>\n",
              "      <td>0.0104</td>\n",
              "      <td>0.0045</td>\n",
              "      <td>0.0014</td>\n",
              "      <td>0.0038</td>\n",
              "      <td>0.0013</td>\n",
              "      <td>0.0089</td>\n",
              "      <td>0.0057</td>\n",
              "      <td>0.0027</td>\n",
              "      <td>0.0051</td>\n",
              "      <td>0.0062</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         0       1       2       3       4   ...      56      57      58      59  60\n",
              "27   0.0177  0.0300  0.0288  0.0394  0.0630  ...  0.0099  0.0057  0.0032  0.0019   R\n",
              "159  0.0235  0.0220  0.0167  0.0516  0.0746  ...  0.0057  0.0052  0.0027  0.0021   M\n",
              "33   0.0442  0.0477  0.0049  0.0581  0.0278  ...  0.0080  0.0105  0.0059  0.0105   R\n",
              "136  0.1088  0.1278  0.0926  0.1234  0.1276  ...  0.0103  0.0205  0.0178  0.0187   M\n",
              "5    0.0286  0.0453  0.0277  0.0174  0.0384  ...  0.0057  0.0027  0.0051  0.0062   R\n",
              "\n",
              "[5 rows x 61 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6BEYnt3Jd8-f",
        "outputId": "d9f97226-c3eb-4c52-a48e-221693b6552f"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 208 entries, 0 to 207\n",
            "Data columns (total 61 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   0       208 non-null    float64\n",
            " 1   1       208 non-null    float64\n",
            " 2   2       208 non-null    float64\n",
            " 3   3       208 non-null    float64\n",
            " 4   4       208 non-null    float64\n",
            " 5   5       208 non-null    float64\n",
            " 6   6       208 non-null    float64\n",
            " 7   7       208 non-null    float64\n",
            " 8   8       208 non-null    float64\n",
            " 9   9       208 non-null    float64\n",
            " 10  10      208 non-null    float64\n",
            " 11  11      208 non-null    float64\n",
            " 12  12      208 non-null    float64\n",
            " 13  13      208 non-null    float64\n",
            " 14  14      208 non-null    float64\n",
            " 15  15      208 non-null    float64\n",
            " 16  16      208 non-null    float64\n",
            " 17  17      208 non-null    float64\n",
            " 18  18      208 non-null    float64\n",
            " 19  19      208 non-null    float64\n",
            " 20  20      208 non-null    float64\n",
            " 21  21      208 non-null    float64\n",
            " 22  22      208 non-null    float64\n",
            " 23  23      208 non-null    float64\n",
            " 24  24      208 non-null    float64\n",
            " 25  25      208 non-null    float64\n",
            " 26  26      208 non-null    float64\n",
            " 27  27      208 non-null    float64\n",
            " 28  28      208 non-null    float64\n",
            " 29  29      208 non-null    float64\n",
            " 30  30      208 non-null    float64\n",
            " 31  31      208 non-null    float64\n",
            " 32  32      208 non-null    float64\n",
            " 33  33      208 non-null    float64\n",
            " 34  34      208 non-null    float64\n",
            " 35  35      208 non-null    float64\n",
            " 36  36      208 non-null    float64\n",
            " 37  37      208 non-null    float64\n",
            " 38  38      208 non-null    float64\n",
            " 39  39      208 non-null    float64\n",
            " 40  40      208 non-null    float64\n",
            " 41  41      208 non-null    float64\n",
            " 42  42      208 non-null    float64\n",
            " 43  43      208 non-null    float64\n",
            " 44  44      208 non-null    float64\n",
            " 45  45      208 non-null    float64\n",
            " 46  46      208 non-null    float64\n",
            " 47  47      208 non-null    float64\n",
            " 48  48      208 non-null    float64\n",
            " 49  49      208 non-null    float64\n",
            " 50  50      208 non-null    float64\n",
            " 51  51      208 non-null    float64\n",
            " 52  52      208 non-null    float64\n",
            " 53  53      208 non-null    float64\n",
            " 54  54      208 non-null    float64\n",
            " 55  55      208 non-null    float64\n",
            " 56  56      208 non-null    float64\n",
            " 57  57      208 non-null    float64\n",
            " 58  58      208 non-null    float64\n",
            " 59  59      208 non-null    float64\n",
            " 60  60      208 non-null    object \n",
            "dtypes: float64(60), object(1)\n",
            "memory usage: 99.2+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chsEaMFUrwaj",
        "outputId": "09e8d1f9-ca81-4f7f-8513-6cab59bf6a17"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(208, 61)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgBF5BVneBaI"
      },
      "source": [
        "df[60].replace({'R':1,'M':0},inplace=True)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "eVD3-gXtrWmu",
        "outputId": "a6cdce67-5230-4dc3-83a6-325508f0ac2e"
      },
      "source": [
        "df.sample(5)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "      <th>43</th>\n",
              "      <th>44</th>\n",
              "      <th>45</th>\n",
              "      <th>46</th>\n",
              "      <th>47</th>\n",
              "      <th>48</th>\n",
              "      <th>49</th>\n",
              "      <th>50</th>\n",
              "      <th>51</th>\n",
              "      <th>52</th>\n",
              "      <th>53</th>\n",
              "      <th>54</th>\n",
              "      <th>55</th>\n",
              "      <th>56</th>\n",
              "      <th>57</th>\n",
              "      <th>58</th>\n",
              "      <th>59</th>\n",
              "      <th>60</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>152</th>\n",
              "      <td>0.0131</td>\n",
              "      <td>0.0201</td>\n",
              "      <td>0.0045</td>\n",
              "      <td>0.0217</td>\n",
              "      <td>0.0230</td>\n",
              "      <td>0.0481</td>\n",
              "      <td>0.0742</td>\n",
              "      <td>0.0333</td>\n",
              "      <td>0.1369</td>\n",
              "      <td>0.2079</td>\n",
              "      <td>0.2295</td>\n",
              "      <td>0.1990</td>\n",
              "      <td>0.1184</td>\n",
              "      <td>0.1891</td>\n",
              "      <td>0.2949</td>\n",
              "      <td>0.5343</td>\n",
              "      <td>0.6850</td>\n",
              "      <td>0.7923</td>\n",
              "      <td>0.8220</td>\n",
              "      <td>0.7290</td>\n",
              "      <td>0.7352</td>\n",
              "      <td>0.7918</td>\n",
              "      <td>0.8057</td>\n",
              "      <td>0.4898</td>\n",
              "      <td>0.1934</td>\n",
              "      <td>0.2924</td>\n",
              "      <td>0.6255</td>\n",
              "      <td>0.8546</td>\n",
              "      <td>0.8966</td>\n",
              "      <td>0.7821</td>\n",
              "      <td>0.5168</td>\n",
              "      <td>0.4840</td>\n",
              "      <td>0.4038</td>\n",
              "      <td>0.3411</td>\n",
              "      <td>0.2849</td>\n",
              "      <td>0.2353</td>\n",
              "      <td>0.2699</td>\n",
              "      <td>0.4442</td>\n",
              "      <td>0.4323</td>\n",
              "      <td>0.3314</td>\n",
              "      <td>0.1195</td>\n",
              "      <td>0.1669</td>\n",
              "      <td>0.3702</td>\n",
              "      <td>0.3072</td>\n",
              "      <td>0.0945</td>\n",
              "      <td>0.1545</td>\n",
              "      <td>0.1394</td>\n",
              "      <td>0.0772</td>\n",
              "      <td>0.0615</td>\n",
              "      <td>0.0230</td>\n",
              "      <td>0.0111</td>\n",
              "      <td>0.0168</td>\n",
              "      <td>0.0086</td>\n",
              "      <td>0.0045</td>\n",
              "      <td>0.0062</td>\n",
              "      <td>0.0065</td>\n",
              "      <td>0.0030</td>\n",
              "      <td>0.0066</td>\n",
              "      <td>0.0029</td>\n",
              "      <td>0.0053</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>180</th>\n",
              "      <td>0.0310</td>\n",
              "      <td>0.0221</td>\n",
              "      <td>0.0433</td>\n",
              "      <td>0.0191</td>\n",
              "      <td>0.0964</td>\n",
              "      <td>0.1827</td>\n",
              "      <td>0.1106</td>\n",
              "      <td>0.1702</td>\n",
              "      <td>0.2804</td>\n",
              "      <td>0.4432</td>\n",
              "      <td>0.5222</td>\n",
              "      <td>0.5611</td>\n",
              "      <td>0.5379</td>\n",
              "      <td>0.4048</td>\n",
              "      <td>0.2245</td>\n",
              "      <td>0.1784</td>\n",
              "      <td>0.2297</td>\n",
              "      <td>0.2720</td>\n",
              "      <td>0.5209</td>\n",
              "      <td>0.6898</td>\n",
              "      <td>0.8202</td>\n",
              "      <td>0.8780</td>\n",
              "      <td>0.7600</td>\n",
              "      <td>0.7616</td>\n",
              "      <td>0.7152</td>\n",
              "      <td>0.7288</td>\n",
              "      <td>0.8686</td>\n",
              "      <td>0.9509</td>\n",
              "      <td>0.8348</td>\n",
              "      <td>0.5730</td>\n",
              "      <td>0.4363</td>\n",
              "      <td>0.4289</td>\n",
              "      <td>0.4240</td>\n",
              "      <td>0.3156</td>\n",
              "      <td>0.1287</td>\n",
              "      <td>0.1477</td>\n",
              "      <td>0.2062</td>\n",
              "      <td>0.2400</td>\n",
              "      <td>0.5173</td>\n",
              "      <td>0.5168</td>\n",
              "      <td>0.1491</td>\n",
              "      <td>0.2407</td>\n",
              "      <td>0.3415</td>\n",
              "      <td>0.4494</td>\n",
              "      <td>0.4624</td>\n",
              "      <td>0.2001</td>\n",
              "      <td>0.0775</td>\n",
              "      <td>0.1232</td>\n",
              "      <td>0.0783</td>\n",
              "      <td>0.0089</td>\n",
              "      <td>0.0249</td>\n",
              "      <td>0.0204</td>\n",
              "      <td>0.0059</td>\n",
              "      <td>0.0053</td>\n",
              "      <td>0.0079</td>\n",
              "      <td>0.0037</td>\n",
              "      <td>0.0015</td>\n",
              "      <td>0.0056</td>\n",
              "      <td>0.0067</td>\n",
              "      <td>0.0054</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>167</th>\n",
              "      <td>0.0137</td>\n",
              "      <td>0.0297</td>\n",
              "      <td>0.0116</td>\n",
              "      <td>0.0082</td>\n",
              "      <td>0.0241</td>\n",
              "      <td>0.0253</td>\n",
              "      <td>0.0279</td>\n",
              "      <td>0.0130</td>\n",
              "      <td>0.0489</td>\n",
              "      <td>0.0874</td>\n",
              "      <td>0.1100</td>\n",
              "      <td>0.1084</td>\n",
              "      <td>0.1094</td>\n",
              "      <td>0.1023</td>\n",
              "      <td>0.0601</td>\n",
              "      <td>0.0906</td>\n",
              "      <td>0.1313</td>\n",
              "      <td>0.2758</td>\n",
              "      <td>0.3660</td>\n",
              "      <td>0.5269</td>\n",
              "      <td>0.5810</td>\n",
              "      <td>0.6181</td>\n",
              "      <td>0.5875</td>\n",
              "      <td>0.4639</td>\n",
              "      <td>0.5424</td>\n",
              "      <td>0.7367</td>\n",
              "      <td>0.9089</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.8247</td>\n",
              "      <td>0.5441</td>\n",
              "      <td>0.3349</td>\n",
              "      <td>0.0877</td>\n",
              "      <td>0.1600</td>\n",
              "      <td>0.4169</td>\n",
              "      <td>0.6576</td>\n",
              "      <td>0.7390</td>\n",
              "      <td>0.7963</td>\n",
              "      <td>0.7493</td>\n",
              "      <td>0.6795</td>\n",
              "      <td>0.4713</td>\n",
              "      <td>0.2355</td>\n",
              "      <td>0.1704</td>\n",
              "      <td>0.2728</td>\n",
              "      <td>0.4016</td>\n",
              "      <td>0.4125</td>\n",
              "      <td>0.3470</td>\n",
              "      <td>0.2739</td>\n",
              "      <td>0.1790</td>\n",
              "      <td>0.0922</td>\n",
              "      <td>0.0276</td>\n",
              "      <td>0.0169</td>\n",
              "      <td>0.0081</td>\n",
              "      <td>0.0040</td>\n",
              "      <td>0.0025</td>\n",
              "      <td>0.0036</td>\n",
              "      <td>0.0058</td>\n",
              "      <td>0.0067</td>\n",
              "      <td>0.0035</td>\n",
              "      <td>0.0043</td>\n",
              "      <td>0.0033</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>0.0207</td>\n",
              "      <td>0.0535</td>\n",
              "      <td>0.0334</td>\n",
              "      <td>0.0818</td>\n",
              "      <td>0.0740</td>\n",
              "      <td>0.0324</td>\n",
              "      <td>0.0918</td>\n",
              "      <td>0.1070</td>\n",
              "      <td>0.1553</td>\n",
              "      <td>0.1234</td>\n",
              "      <td>0.1796</td>\n",
              "      <td>0.1787</td>\n",
              "      <td>0.1247</td>\n",
              "      <td>0.2577</td>\n",
              "      <td>0.3370</td>\n",
              "      <td>0.3990</td>\n",
              "      <td>0.1647</td>\n",
              "      <td>0.2266</td>\n",
              "      <td>0.3219</td>\n",
              "      <td>0.5356</td>\n",
              "      <td>0.8159</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.8701</td>\n",
              "      <td>0.6889</td>\n",
              "      <td>0.6299</td>\n",
              "      <td>0.5738</td>\n",
              "      <td>0.5707</td>\n",
              "      <td>0.5976</td>\n",
              "      <td>0.4301</td>\n",
              "      <td>0.2058</td>\n",
              "      <td>0.1000</td>\n",
              "      <td>0.2247</td>\n",
              "      <td>0.2308</td>\n",
              "      <td>0.3977</td>\n",
              "      <td>0.3317</td>\n",
              "      <td>0.1726</td>\n",
              "      <td>0.1429</td>\n",
              "      <td>0.2168</td>\n",
              "      <td>0.1967</td>\n",
              "      <td>0.2140</td>\n",
              "      <td>0.3674</td>\n",
              "      <td>0.2023</td>\n",
              "      <td>0.0778</td>\n",
              "      <td>0.0925</td>\n",
              "      <td>0.2388</td>\n",
              "      <td>0.3400</td>\n",
              "      <td>0.2594</td>\n",
              "      <td>0.1102</td>\n",
              "      <td>0.0911</td>\n",
              "      <td>0.0462</td>\n",
              "      <td>0.0171</td>\n",
              "      <td>0.0033</td>\n",
              "      <td>0.0050</td>\n",
              "      <td>0.0190</td>\n",
              "      <td>0.0103</td>\n",
              "      <td>0.0121</td>\n",
              "      <td>0.0042</td>\n",
              "      <td>0.0090</td>\n",
              "      <td>0.0070</td>\n",
              "      <td>0.0099</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>0.0109</td>\n",
              "      <td>0.0093</td>\n",
              "      <td>0.0121</td>\n",
              "      <td>0.0378</td>\n",
              "      <td>0.0679</td>\n",
              "      <td>0.0863</td>\n",
              "      <td>0.1004</td>\n",
              "      <td>0.0664</td>\n",
              "      <td>0.0941</td>\n",
              "      <td>0.1036</td>\n",
              "      <td>0.0972</td>\n",
              "      <td>0.0501</td>\n",
              "      <td>0.1546</td>\n",
              "      <td>0.3404</td>\n",
              "      <td>0.4804</td>\n",
              "      <td>0.6570</td>\n",
              "      <td>0.7738</td>\n",
              "      <td>0.7827</td>\n",
              "      <td>0.8152</td>\n",
              "      <td>0.8129</td>\n",
              "      <td>0.8297</td>\n",
              "      <td>0.8535</td>\n",
              "      <td>0.8870</td>\n",
              "      <td>0.8894</td>\n",
              "      <td>0.8980</td>\n",
              "      <td>0.9667</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.9134</td>\n",
              "      <td>0.6762</td>\n",
              "      <td>0.4659</td>\n",
              "      <td>0.2895</td>\n",
              "      <td>0.2959</td>\n",
              "      <td>0.1746</td>\n",
              "      <td>0.2112</td>\n",
              "      <td>0.2569</td>\n",
              "      <td>0.2276</td>\n",
              "      <td>0.2149</td>\n",
              "      <td>0.1601</td>\n",
              "      <td>0.0371</td>\n",
              "      <td>0.0117</td>\n",
              "      <td>0.0488</td>\n",
              "      <td>0.0288</td>\n",
              "      <td>0.0597</td>\n",
              "      <td>0.0431</td>\n",
              "      <td>0.0369</td>\n",
              "      <td>0.0025</td>\n",
              "      <td>0.0327</td>\n",
              "      <td>0.0257</td>\n",
              "      <td>0.0182</td>\n",
              "      <td>0.0108</td>\n",
              "      <td>0.0124</td>\n",
              "      <td>0.0077</td>\n",
              "      <td>0.0023</td>\n",
              "      <td>0.0117</td>\n",
              "      <td>0.0053</td>\n",
              "      <td>0.0077</td>\n",
              "      <td>0.0076</td>\n",
              "      <td>0.0056</td>\n",
              "      <td>0.0055</td>\n",
              "      <td>0.0039</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         0       1       2       3       4   ...      56      57      58      59  60\n",
              "152  0.0131  0.0201  0.0045  0.0217  0.0230  ...  0.0030  0.0066  0.0029  0.0053   0\n",
              "180  0.0310  0.0221  0.0433  0.0191  0.0964  ...  0.0015  0.0056  0.0067  0.0054   0\n",
              "167  0.0137  0.0297  0.0116  0.0082  0.0241  ...  0.0067  0.0035  0.0043  0.0033   0\n",
              "149  0.0207  0.0535  0.0334  0.0818  0.0740  ...  0.0042  0.0090  0.0070  0.0099   0\n",
              "74   0.0109  0.0093  0.0121  0.0378  0.0679  ...  0.0076  0.0056  0.0055  0.0039   1\n",
              "\n",
              "[5 rows x 61 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iN9DflYZr5tZ",
        "outputId": "626cf312-412e-4af2-ac9d-11213d232e19"
      },
      "source": [
        "df[60].value_counts()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    111\n",
              "1     97\n",
              "Name: 60, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGobnO87r_47"
      },
      "source": [
        "X = df.drop(60, axis=1)\n",
        "Y  = df[60]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-E5UDYo0sKXp"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.25,random_state=5)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IgYi7zmzsoB4",
        "outputId": "c16333e3-c85c-448a-c9d6-32c586d7b7b9"
      },
      "source": [
        "X_train.shape, X_test.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((156, 60), (52, 60))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3C4Vh6NMsvPn"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVSXmTeys2oZ",
        "outputId": "92f26a37-1adc-4149-b43d-a80feb94d812"
      },
      "source": [
        "model = keras.Sequential([\n",
        "            keras.layers.Dense(60, input_dim=60,activation='relu'),\n",
        "            keras.layers.Dense(30,activation='relu'),\n",
        "            keras.layers.Dense(15,activation='relu'),\n",
        "            keras.layers.Dense(1,activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, Y_train, epochs=100, batch_size=8)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "20/20 [==============================] - 1s 2ms/step - loss: 0.6930 - accuracy: 0.5128\n",
            "Epoch 2/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6710 - accuracy: 0.6026\n",
            "Epoch 3/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6519 - accuracy: 0.6474\n",
            "Epoch 4/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6412 - accuracy: 0.6667\n",
            "Epoch 5/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6051 - accuracy: 0.7244\n",
            "Epoch 6/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5731 - accuracy: 0.7756\n",
            "Epoch 7/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5439 - accuracy: 0.7821\n",
            "Epoch 8/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5164 - accuracy: 0.7949\n",
            "Epoch 9/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4930 - accuracy: 0.7821\n",
            "Epoch 10/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4724 - accuracy: 0.7949\n",
            "Epoch 11/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4513 - accuracy: 0.8077\n",
            "Epoch 12/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4431 - accuracy: 0.7564\n",
            "Epoch 13/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4232 - accuracy: 0.8077\n",
            "Epoch 14/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.3909 - accuracy: 0.8718\n",
            "Epoch 15/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.3929 - accuracy: 0.8462\n",
            "Epoch 16/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.3808 - accuracy: 0.8077\n",
            "Epoch 17/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.3498 - accuracy: 0.8718\n",
            "Epoch 18/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.3410 - accuracy: 0.8590\n",
            "Epoch 19/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.3224 - accuracy: 0.8718\n",
            "Epoch 20/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.3282 - accuracy: 0.8974\n",
            "Epoch 21/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.3073 - accuracy: 0.8910\n",
            "Epoch 22/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.3042 - accuracy: 0.8526\n",
            "Epoch 23/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.3362 - accuracy: 0.8526\n",
            "Epoch 24/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2640 - accuracy: 0.9038\n",
            "Epoch 25/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2475 - accuracy: 0.9295\n",
            "Epoch 26/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2368 - accuracy: 0.9231\n",
            "Epoch 27/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2440 - accuracy: 0.9103\n",
            "Epoch 28/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2450 - accuracy: 0.8974\n",
            "Epoch 29/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2227 - accuracy: 0.9423\n",
            "Epoch 30/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2136 - accuracy: 0.9167\n",
            "Epoch 31/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.1992 - accuracy: 0.9423\n",
            "Epoch 32/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2257 - accuracy: 0.9167\n",
            "Epoch 33/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.1723 - accuracy: 0.9423\n",
            "Epoch 34/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.1697 - accuracy: 0.9423\n",
            "Epoch 35/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.1775 - accuracy: 0.9038\n",
            "Epoch 36/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.1533 - accuracy: 0.9551\n",
            "Epoch 37/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.1530 - accuracy: 0.9551\n",
            "Epoch 38/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.1457 - accuracy: 0.9551\n",
            "Epoch 39/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.1296 - accuracy: 0.9551\n",
            "Epoch 40/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.1069 - accuracy: 0.9744\n",
            "Epoch 41/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.1400 - accuracy: 0.9359\n",
            "Epoch 42/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.1364 - accuracy: 0.9551\n",
            "Epoch 43/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.1334 - accuracy: 0.9615\n",
            "Epoch 44/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.1220 - accuracy: 0.9551\n",
            "Epoch 45/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0906 - accuracy: 0.9744\n",
            "Epoch 46/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0853 - accuracy: 0.9808\n",
            "Epoch 47/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0781 - accuracy: 0.9808\n",
            "Epoch 48/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0759 - accuracy: 0.9744\n",
            "Epoch 49/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0744 - accuracy: 0.9936\n",
            "Epoch 50/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0882 - accuracy: 0.9615\n",
            "Epoch 51/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0771 - accuracy: 0.9936\n",
            "Epoch 52/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0697 - accuracy: 0.9872\n",
            "Epoch 53/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0538 - accuracy: 1.0000\n",
            "Epoch 54/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0394 - accuracy: 1.0000\n",
            "Epoch 55/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0415 - accuracy: 0.9936\n",
            "Epoch 56/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0394 - accuracy: 0.9936\n",
            "Epoch 57/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0453 - accuracy: 0.9936\n",
            "Epoch 58/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0486 - accuracy: 0.9936\n",
            "Epoch 59/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0331 - accuracy: 1.0000\n",
            "Epoch 60/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0326 - accuracy: 1.0000\n",
            "Epoch 61/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0269 - accuracy: 1.0000\n",
            "Epoch 62/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0232 - accuracy: 1.0000\n",
            "Epoch 63/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0238 - accuracy: 1.0000\n",
            "Epoch 64/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0229 - accuracy: 1.0000\n",
            "Epoch 65/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0180 - accuracy: 1.0000\n",
            "Epoch 66/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0167 - accuracy: 1.0000\n",
            "Epoch 67/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0159 - accuracy: 1.0000\n",
            "Epoch 68/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0159 - accuracy: 1.0000\n",
            "Epoch 69/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.0147 - accuracy: 1.0000\n",
            "Epoch 70/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0148 - accuracy: 1.0000\n",
            "Epoch 71/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0163 - accuracy: 1.0000\n",
            "Epoch 72/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0143 - accuracy: 1.0000\n",
            "Epoch 73/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0107 - accuracy: 1.0000\n",
            "Epoch 74/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0097 - accuracy: 1.0000\n",
            "Epoch 75/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0092 - accuracy: 1.0000\n",
            "Epoch 76/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0084 - accuracy: 1.0000\n",
            "Epoch 77/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0091 - accuracy: 1.0000\n",
            "Epoch 78/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0099 - accuracy: 1.0000\n",
            "Epoch 79/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0097 - accuracy: 1.0000\n",
            "Epoch 80/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0069 - accuracy: 1.0000\n",
            "Epoch 81/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0063 - accuracy: 1.0000\n",
            "Epoch 82/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0063 - accuracy: 1.0000\n",
            "Epoch 83/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0064 - accuracy: 1.0000\n",
            "Epoch 84/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0057 - accuracy: 1.0000\n",
            "Epoch 85/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0065 - accuracy: 1.0000\n",
            "Epoch 86/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0070 - accuracy: 1.0000\n",
            "Epoch 87/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0061 - accuracy: 1.0000\n",
            "Epoch 88/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0055 - accuracy: 1.0000\n",
            "Epoch 89/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0050 - accuracy: 1.0000\n",
            "Epoch 90/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0044 - accuracy: 1.0000\n",
            "Epoch 91/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0056 - accuracy: 1.0000\n",
            "Epoch 92/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0046 - accuracy: 1.0000\n",
            "Epoch 93/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0040 - accuracy: 1.0000\n",
            "Epoch 94/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0035 - accuracy: 1.0000\n",
            "Epoch 95/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0035 - accuracy: 1.0000\n",
            "Epoch 96/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "Epoch 97/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0035 - accuracy: 1.0000\n",
            "Epoch 98/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0031 - accuracy: 1.0000\n",
            "Epoch 99/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0031 - accuracy: 1.0000\n",
            "Epoch 100/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0031 - accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2971162e90>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0UMABvRyPjR",
        "outputId": "55e75e78-f1b7-41b2-850f-8d37961f950c"
      },
      "source": [
        "model.evaluate(X_test,Y_test)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5265 - accuracy: 0.8654\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5264717936515808, 0.8653846383094788]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czrmkS9JfbQa",
        "outputId": "1cd87273-61a9-474e-d3a0-8ccfe75b6981"
      },
      "source": [
        "y_pred = model.predict(X_test).reshape(-1)\n",
        "y_pred"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.0566199e-05, 9.9519223e-01, 2.1642101e-01, 1.2972629e-01,\n",
              "       9.9276042e-01, 1.0600273e-05, 9.1322982e-01, 9.9999678e-01,\n",
              "       3.0720234e-04, 9.9999744e-01, 3.1038225e-03, 8.5741043e-02,\n",
              "       1.0000000e+00, 8.6747372e-05, 5.5914044e-02, 8.6859077e-02,\n",
              "       5.6908569e-08, 1.6494672e-05, 9.1514063e-05, 8.1794262e-03,\n",
              "       7.0547713e-07, 8.6049855e-02, 5.1233441e-02, 2.5760084e-02,\n",
              "       7.0020705e-02, 3.0393362e-01, 9.9967575e-01, 5.0815940e-04,\n",
              "       7.2558081e-01, 4.5597812e-06, 8.5386555e-06, 3.9127469e-04,\n",
              "       9.9578846e-01, 2.9618800e-02, 9.9979746e-01, 8.7600744e-01,\n",
              "       9.7609554e-05, 5.0167837e-06, 2.2119284e-04, 9.9999917e-01,\n",
              "       9.9999750e-01, 9.9951249e-01, 9.9998832e-01, 9.1568959e-01,\n",
              "       6.2395275e-02, 9.8486578e-01, 4.0090322e-02, 9.6698344e-01,\n",
              "       1.6948199e-01, 9.9999952e-01, 3.7464213e-07, 5.6855328e-07],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2BaLA6-qye2w",
        "outputId": "fe5dc5c2-cd97-4856-dd26-e602bd56bde8"
      },
      "source": [
        "y_pred = np.round(y_pred)\n",
        "y_pred"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0.,\n",
              "       1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
              "       0.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jG55KGHKy9Xc",
        "outputId": "a5ff7d6b-a3cb-4b2d-aa69-5241febdc3ab"
      },
      "source": [
        "Y_test"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "156    0\n",
              "21     1\n",
              "193    0\n",
              "159    0\n",
              "34     1\n",
              "196    0\n",
              "6      1\n",
              "25     1\n",
              "115    0\n",
              "51     1\n",
              "119    0\n",
              "26     1\n",
              "42     1\n",
              "199    0\n",
              "153    0\n",
              "151    0\n",
              "186    0\n",
              "202    0\n",
              "111    0\n",
              "149    0\n",
              "142    0\n",
              "154    0\n",
              "173    0\n",
              "116    0\n",
              "127    0\n",
              "28     1\n",
              "3      1\n",
              "166    0\n",
              "56     1\n",
              "141    0\n",
              "187    0\n",
              "117    0\n",
              "101    0\n",
              "123    0\n",
              "89     1\n",
              "150    0\n",
              "192    0\n",
              "161    0\n",
              "17     1\n",
              "95     1\n",
              "39     1\n",
              "53     1\n",
              "40     1\n",
              "48     1\n",
              "46     1\n",
              "54     1\n",
              "207    0\n",
              "178    0\n",
              "205    0\n",
              "24     1\n",
              "136    0\n",
              "185    0\n",
              "Name: 60, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qt2mRSqvzB0n",
        "outputId": "f5d1bb2e-9c56-4500-8d28-7ed6d95a44fa"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(Y_test,y_pred))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.91      0.89        32\n",
            "           1       0.84      0.80      0.82        20\n",
            "\n",
            "    accuracy                           0.87        52\n",
            "   macro avg       0.86      0.85      0.86        52\n",
            "weighted avg       0.86      0.87      0.86        52\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfi2N1oHzbNy"
      },
      "source": [
        "Now we'll use dropout regularization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PDKgEp6zef4",
        "outputId": "d5719473-0d67-4679-bf53-f6dd9ee455eb"
      },
      "source": [
        "model_d = keras.Sequential([\n",
        "            keras.layers.Dense(60, input_dim=60,activation='relu'),\n",
        "            keras.layers.Dropout(0.5),\n",
        "            keras.layers.Dense(30,activation='relu'),\n",
        "            keras.layers.Dropout(0.2),\n",
        "            keras.layers.Dense(15,activation='relu'),\n",
        "            keras.layers.Dropout(0.2),\n",
        "            keras.layers.Dense(1,activation='sigmoid')\n",
        "])\n",
        "\n",
        "model_d.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model_d.fit(X_train, Y_train, epochs=100, batch_size=8)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "20/20 [==============================] - 1s 2ms/step - loss: 0.7373 - accuracy: 0.5192\n",
            "Epoch 2/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.7003 - accuracy: 0.5000\n",
            "Epoch 3/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6904 - accuracy: 0.5192\n",
            "Epoch 4/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6782 - accuracy: 0.5385\n",
            "Epoch 5/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6792 - accuracy: 0.5385\n",
            "Epoch 6/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6770 - accuracy: 0.5641\n",
            "Epoch 7/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6785 - accuracy: 0.5705\n",
            "Epoch 8/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6504 - accuracy: 0.6731\n",
            "Epoch 9/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6503 - accuracy: 0.6410\n",
            "Epoch 10/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6654 - accuracy: 0.5705\n",
            "Epoch 11/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6236 - accuracy: 0.6731\n",
            "Epoch 12/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6227 - accuracy: 0.6218\n",
            "Epoch 13/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.6193 - accuracy: 0.7051\n",
            "Epoch 14/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6291 - accuracy: 0.6538\n",
            "Epoch 15/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6111 - accuracy: 0.6859\n",
            "Epoch 16/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5782 - accuracy: 0.7179\n",
            "Epoch 17/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.6002 - accuracy: 0.6667\n",
            "Epoch 18/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5990 - accuracy: 0.6538\n",
            "Epoch 19/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5574 - accuracy: 0.7564\n",
            "Epoch 20/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5595 - accuracy: 0.6923\n",
            "Epoch 21/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5948 - accuracy: 0.7244\n",
            "Epoch 22/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5490 - accuracy: 0.7051\n",
            "Epoch 23/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5173 - accuracy: 0.7756\n",
            "Epoch 24/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5267 - accuracy: 0.7051\n",
            "Epoch 25/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5409 - accuracy: 0.7372\n",
            "Epoch 26/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7628\n",
            "Epoch 27/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5546 - accuracy: 0.6859\n",
            "Epoch 28/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.7628\n",
            "Epoch 29/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5022 - accuracy: 0.7628\n",
            "Epoch 30/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4856 - accuracy: 0.7500\n",
            "Epoch 31/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4348 - accuracy: 0.8397\n",
            "Epoch 32/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4667 - accuracy: 0.7372\n",
            "Epoch 33/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4933 - accuracy: 0.7949\n",
            "Epoch 34/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4941 - accuracy: 0.7564\n",
            "Epoch 35/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4719 - accuracy: 0.7756\n",
            "Epoch 36/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5096 - accuracy: 0.7372\n",
            "Epoch 37/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.7692\n",
            "Epoch 38/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.3950 - accuracy: 0.8462\n",
            "Epoch 39/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4461 - accuracy: 0.7885\n",
            "Epoch 40/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.3883 - accuracy: 0.8269\n",
            "Epoch 41/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4527 - accuracy: 0.8205\n",
            "Epoch 42/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4088 - accuracy: 0.8205\n",
            "Epoch 43/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4365 - accuracy: 0.7949\n",
            "Epoch 44/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.3743 - accuracy: 0.8397\n",
            "Epoch 45/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.3418 - accuracy: 0.8590\n",
            "Epoch 46/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.3465 - accuracy: 0.8333\n",
            "Epoch 47/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4120 - accuracy: 0.8333\n",
            "Epoch 48/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4569 - accuracy: 0.8141\n",
            "Epoch 49/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.3750 - accuracy: 0.8590\n",
            "Epoch 50/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4002 - accuracy: 0.8141\n",
            "Epoch 51/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.3453 - accuracy: 0.8397\n",
            "Epoch 52/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.3265 - accuracy: 0.8526\n",
            "Epoch 53/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.3332 - accuracy: 0.8333\n",
            "Epoch 54/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.3714 - accuracy: 0.8654\n",
            "Epoch 55/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.3248 - accuracy: 0.8397\n",
            "Epoch 56/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.3316 - accuracy: 0.8269\n",
            "Epoch 57/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2673 - accuracy: 0.8718\n",
            "Epoch 58/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2698 - accuracy: 0.9038\n",
            "Epoch 59/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.3079 - accuracy: 0.8782\n",
            "Epoch 60/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.3065 - accuracy: 0.8654\n",
            "Epoch 61/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2918 - accuracy: 0.8654\n",
            "Epoch 62/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2735 - accuracy: 0.8974\n",
            "Epoch 63/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.3204 - accuracy: 0.8846\n",
            "Epoch 64/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2859 - accuracy: 0.8782\n",
            "Epoch 65/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.3449 - accuracy: 0.8397\n",
            "Epoch 66/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2562 - accuracy: 0.9038\n",
            "Epoch 67/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2756 - accuracy: 0.8718\n",
            "Epoch 68/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2888 - accuracy: 0.8782\n",
            "Epoch 69/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2890 - accuracy: 0.8654\n",
            "Epoch 70/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2822 - accuracy: 0.8910\n",
            "Epoch 71/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2743 - accuracy: 0.9038\n",
            "Epoch 72/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2588 - accuracy: 0.8974\n",
            "Epoch 73/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2409 - accuracy: 0.9231\n",
            "Epoch 74/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.3302 - accuracy: 0.8590\n",
            "Epoch 75/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2638 - accuracy: 0.8846\n",
            "Epoch 76/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2502 - accuracy: 0.8910\n",
            "Epoch 77/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2417 - accuracy: 0.9103\n",
            "Epoch 78/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2710 - accuracy: 0.8910\n",
            "Epoch 79/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2351 - accuracy: 0.9103\n",
            "Epoch 80/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.1987 - accuracy: 0.9359\n",
            "Epoch 81/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2044 - accuracy: 0.9423\n",
            "Epoch 82/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2640 - accuracy: 0.9103\n",
            "Epoch 83/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2208 - accuracy: 0.9423\n",
            "Epoch 84/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.1656 - accuracy: 0.9167\n",
            "Epoch 85/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2497 - accuracy: 0.9038\n",
            "Epoch 86/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2039 - accuracy: 0.9167\n",
            "Epoch 87/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2317 - accuracy: 0.8846\n",
            "Epoch 88/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2461 - accuracy: 0.9038\n",
            "Epoch 89/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.1923 - accuracy: 0.9295\n",
            "Epoch 90/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2478 - accuracy: 0.8974\n",
            "Epoch 91/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2338 - accuracy: 0.9231\n",
            "Epoch 92/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2418 - accuracy: 0.9038\n",
            "Epoch 93/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2430 - accuracy: 0.8910\n",
            "Epoch 94/100\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2175 - accuracy: 0.9103\n",
            "Epoch 95/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2087 - accuracy: 0.9103\n",
            "Epoch 96/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.1902 - accuracy: 0.9231\n",
            "Epoch 97/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.1819 - accuracy: 0.9359\n",
            "Epoch 98/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.1670 - accuracy: 0.9231\n",
            "Epoch 99/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.1530 - accuracy: 0.9551\n",
            "Epoch 100/100\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.1565 - accuracy: 0.9679\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2971067ad0>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r80WEWMZz0DZ",
        "outputId": "0294672f-71ae-4244-e85b-aab40e899715"
      },
      "source": [
        "model_d.evaluate(X_test,Y_test)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 6ms/step - loss: 0.2999 - accuracy: 0.9038\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.29992544651031494, 0.9038461446762085]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBiz7Zku0MXD",
        "outputId": "7e996b90-6c00-47f8-b33a-1296bc3d7789"
      },
      "source": [
        "y_pred = model_d.predict(X_test).reshape(-1)\n",
        "y_pred = np.round(y_pred)\n",
        "print(classification_report(Y_test,y_pred))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.94      0.92        32\n",
            "           1       0.89      0.85      0.87        20\n",
            "\n",
            "    accuracy                           0.90        52\n",
            "   macro avg       0.90      0.89      0.90        52\n",
            "weighted avg       0.90      0.90      0.90        52\n",
            "\n"
          ]
        }
      ]
    }
  ]
}